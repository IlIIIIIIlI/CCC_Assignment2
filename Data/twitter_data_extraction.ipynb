{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:27:28.353768Z",
     "end_time": "2023-04-30T21:27:28.410505Z"
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "city_file = 'sal.json'\n",
    "file_name = 'demo.json'\n",
    "city_dict = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:28:23.234937Z",
     "end_time": "2023-04-30T21:28:23.245335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# def whether_process(full_name, city_dict):\n",
    "#     out = False\n",
    "#     wrong_list = ['australia', 'new south wales', 'queensland', 'victoria', 'western australia', 'south australia',\n",
    "#                   'tasmania',\n",
    "#                   '\taustralian capital territory', 'northern territory']\n",
    "#     if full_name not in wrong_list:\n",
    "#         if full_name in city_dict.keys():\n",
    "#             out = True\n",
    "#     return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T19:51:55.052930Z",
     "end_time": "2023-04-22T19:51:55.077356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# import ijson\n",
    "# # Load city data\n",
    "# with open(city_file, 'r', encoding='utf-8') as sal_file:\n",
    "#     for prefix, event, value in ijson.parse(sal_file):\n",
    "#         if prefix.endswith('.gcc'):\n",
    "#             location = prefix.split('.')[0]\n",
    "#             if value[1] == 'g' or value == '8acte':\n",
    "#                 city_dict[location] = value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T19:55:02.136679Z",
     "end_time": "2023-04-22T19:55:02.210589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "\n",
    "def split_time_by_period(timestamp):\n",
    "    # 将时间戳字符串转换为datetime对象\n",
    "    dt = parser.parse(timestamp)\n",
    "\n",
    "    # 获取小时部分\n",
    "    hour = dt.hour\n",
    "\n",
    "    # 根据小时划分时间段\n",
    "    if 3 < hour <= 11:\n",
    "        period = \"morning\"\n",
    "    elif 11 <= hour < 19:\n",
    "        period = \"afternoon\"\n",
    "    else:\n",
    "        period = \"evening\"\n",
    "\n",
    "    return period\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:27:32.149321Z",
     "end_time": "2023-04-30T21:27:32.158278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "def sentiment_m1(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    return labels[ranking[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:27:32.909619Z",
     "end_time": "2023-04-30T21:27:51.890392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 读取 JSON 文件并提取字段写入新的 JSON 文件\n",
    "with open(file_name, 'r') as f_in, open(\"final.json\", \"w\") as outfile:\n",
    "    # 跳过第一行\n",
    "    f_in.readline()\n",
    "    # 逐行读取并解析 JSON\n",
    "    counter = 1\n",
    "    for line in f_in:\n",
    "        # 解析 JSON\n",
    "        original_data = json.loads(line)\n",
    "        # 获取时间戳\n",
    "        timestamp = original_data[\"created_at\"]\n",
    "\n",
    "       # 计算时间段\n",
    "        period = split_time_by_period(timestamp)\n",
    "        sentiment = sentiment_m1(original_data[\"text\"])\n",
    "\n",
    "        new_data = {\n",
    "        \"id\": original_data[\"id\"],\n",
    "        \"GCC\": original_data[\"GCC\"],\n",
    "        'full_name' : original_data[\"includes\"][\"places\"][0][\"full_name\"],\n",
    "        \"bbox\": original_data[\"includes\"][\"places\"][0][\"geo\"][\"bbox\"][:2],\n",
    "        \"text\": original_data[\"text\"],\n",
    "        \"tokens\": original_data[\"value\"][\"tokens\"],\n",
    "        \"author_id\": original_data[\"author_id\"],\n",
    "        \"context_annotations\": original_data[\"context_annotations\"],\n",
    "        \"created_at\": original_data[\"created_at\"],\n",
    "        \"retweet_count\": original_data[\"public_metrics\"][\"retweet_count\"],\n",
    "        \"reply_count\": original_data[\"public_metrics\"][\"reply_count\"],\n",
    "        \"like_count\": original_data[\"public_metrics\"][\"like_count\"],\n",
    "        \"quote_count\": original_data[\"public_metrics\"][\"quote_count\"],\n",
    "\n",
    "        \"lang\": original_data[\"lang\"],\n",
    "        \"time_period\": period,\n",
    "\n",
    "        'sentiment' : sentiment\n",
    "        }\n",
    "        counter += 1\n",
    "        if counter % 100000 == 0:\n",
    "            print(counter)\n",
    "        outfile.write(json.dumps(new_data, ensure_ascii=False))\n",
    "        outfile.write('\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T21:34:41.616879Z",
     "end_time": "2023-04-30T21:34:41.900705Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "All data have been saved!\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:54:07.247370Z",
     "end_time": "2023-04-23T19:37:18.007173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684134\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T16:53:53.569361Z",
     "end_time": "2023-04-23T16:53:53.580825Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
